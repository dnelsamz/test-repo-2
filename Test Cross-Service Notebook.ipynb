{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b62051",
   "metadata": {},
   "source": [
    "This cross-service notebook will walk you through the process of using Textract's DetectDocumenText API to extract text from a PNG file containing text, and then using Comprehend's DetectEntities API to find entities in the text extracted from a JPG/JPEG/PNG image file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c58983",
   "metadata": {},
   "source": [
    "In order to make use of the Boto3 Python SDK, you will need to configure your AWS credentials. In the code cell below, replace \"KeyID\" with the value of your AWS Key ID and replace \"AccessKey\" with the value of your AWS Secret Access Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure set aws_access_key_id \"KeyID\"\n",
    "!aws configure set aws_secret_access_key \"AccessKey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99c2e4",
   "metadata": {},
   "source": [
    "After setting your security credentials, you will need to import any libraries you need. You will also need to set the name of both the S3 bucket you have your image in and the name of the image itself. In the code below, replace the value of \"bucket-name\" with the name of your bucket, replace the value of \"document-name\" with the name of the image file you want to analyze, and replace the value of \"region\" with the name of the region you are operating in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from PIL import Image               \n",
    "from IPython.display import display \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "bucket = 'bucket-name'\n",
    "document = 'document-name'\n",
    "region = 'region'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbdf9a",
   "metadata": {},
   "source": [
    "You'll need to create a function that connects to both S3 and Textract via the Boto3 SDK. The function presented in the following code starts by connecting to the S3 resource and retrieving the image you specified from the bucket you specified. The function then connects to Textract and calls the DetectDocumentText API to extract the text in the image. The lines of text found in the document are stored in a list and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_detection(bucket, document):\n",
    "    # Get the document from S3\n",
    "    s3_connection = boto3.resource('s3')\n",
    "\n",
    "    s3_object = s3_connection.Object(bucket, document)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    # opening binary stream using an in-memory bytes buffer\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    # loading stream into image\n",
    "    image = Image.open(stream)\n",
    "\n",
    "    # Detect text in the document\n",
    "    client = boto3.client('textract', region_name=region)\n",
    "\n",
    "    # process using S3 object\n",
    "    response = client.detect_document_text(\n",
    "        Document={'S3Object': {'Bucket': bucket, 'Name': document}})\n",
    "\n",
    "    # Get the text blocks\n",
    "    blocks = response['Blocks']\n",
    "\n",
    "    # List to store image lines in document\n",
    "    line_list = []\n",
    "\n",
    "    # Create image showing bounding box/polygon the detected lines/text\n",
    "    for block in blocks:\n",
    "        if block[\"BlockType\"] == \"LINE\":\n",
    "            line_list.append(block[\"Text\"])\n",
    "\n",
    "    # Display the image\n",
    "    display(image)\n",
    "    return line_list\n",
    "\n",
    "lines = process_text_detection(bucket, document)\n",
    "print(\"Text found: \" + str(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a891bc8",
   "metadata": {},
   "source": [
    "You can now send the lines you extracted from the image to Comprehend and use the service's DetectEntities API to find all entities within those lines. You'll need a function that iteratres through the list of lines returned by the \"process_text_detection\" function you wrote earlier and calls the DetectEntities operation on every line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the entities found for every line\n",
    "response_entities = []\n",
    "\n",
    "# Connect to comprehend\n",
    "comprehend = boto3.client(service_name='comprehend', region_name=region)\n",
    "\n",
    "print('Calling DetectEntities:')\n",
    "print(\"------\")\n",
    "# Iterate through the lines in the list of lines\n",
    "for line in lines:\n",
    "\n",
    "    # construct a list to hold all found entities for a single line\n",
    "    entities_list = []\n",
    "\n",
    "    # Call the DetectEntities operation and pass it a line from lines\n",
    "    found_entities = comprehend.detect_entities(Text=line, LanguageCode='en')\n",
    "    for response_data, values in found_entities.items():\n",
    "        for item in values:\n",
    "            if \"Text\" in item:\n",
    "                print(\"Entities found:\")\n",
    "                for text, val in item.items():\n",
    "                    if text == \"Text\":\n",
    "                        # Append the found entities to the list of entities\n",
    "                        entities_list.append(val)\n",
    "                        print(val)\n",
    "    # Add all found entities for this line to the list of all entities found\n",
    "    response_entities.append(entities_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca38c9",
   "metadata": {},
   "source": [
    "Now that you have a list of the lines extracted by Textract and the entities found in those lines, you can create a dataframe that lets you see both. In the code below, a Pandas dataframe is constructed, displaying the lines found in the input image and their associated entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_dict = {\"Lines\":lines, \"Entities\":response_entities}\n",
    "df = pd.DataFrame(entities_dict, columns=[\"Lines\",\"Entities\"])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
